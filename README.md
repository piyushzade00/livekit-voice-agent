---

#Ô∏è Real-Time Voice Agent (LiveKit)

A real-time voice agent built using **LiveKit (Python SDK)** that joins a room, listens to user speech, converts it to text, responds with `"You said: <text>"`, and plays the response back via audio.

The agent supports:

* Speech-to-Text (STT)
* Text-to-Speech (TTS)
* Voice Activity Detection (VAD)
* Immediate interruption (No Overlap)
* Silence reminder after 20 seconds

---

# Features

## Option B Implementation (STT ‚Üí Response ‚Üí TTS)

* Captures live audio from LiveKit room
* Converts speech to text using AssemblyAI
* Generates response: `"You said: <text>"`
* Converts response to speech using gTTS
* Streams audio back in real time

---

## No Overlap Handling (Required)

The agent:

* Detects user speech using RMS-based Voice Activity Detection (VAD)
* Immediately cancels bot speech if the user starts speaking
* Uses async task cancellation for real-time interruption
* Maintains speaking-state flags to prevent overlap

---

## Silence Handling (Required)

* Tracks last detected user speech

* If no speech for 20+ seconds ‚Üí plays reminder:

  "Are you still there?"

* Does not continuously loop or spam audio

* Uses background async silence monitor task

---

# Project Structure

```
voice-agent-python/
‚îÇ
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ config.example.py
‚îÇ
‚îú‚îÄ‚îÄ agent/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ voice_agent.py
‚îÇ   ‚îú‚îÄ‚îÄ vad.py
‚îÇ   ‚îú‚îÄ‚îÄ stt.py
‚îÇ   ‚îú‚îÄ‚îÄ tts.py
‚îÇ   ‚îî‚îÄ‚îÄ silence.py
```

### Architecture Overview

* `voice_agent.py` ‚Üí Core orchestration
* `vad.py` ‚Üí Audio receiving & voice detection
* `stt.py` ‚Üí AssemblyAI integration
* `tts.py` ‚Üí TTS generation & audio streaming
* `silence.py` ‚Üí Silence monitoring logic

The design is modular and event-driven using `asyncio`.

---

# SDK Used

* **LiveKit Python SDK**
* AsyncIO (Python built-in)
* NumPy (RMS energy calculation)

---

# External Services Used

| Service        | Purpose              |
| -------------- | -------------------- |
| LiveKit Cloud  | Real-time audio room |
| AssemblyAI API | Speech-to-Text       |
| gTTS           | Text-to-Speech       |

---

# Setup Instructions

## 1Ô∏è‚É£ Clone Repository

```bash
git clone <your-repo-url>
cd voice-agent-python
```

---

## 2Ô∏è‚É£ Create Virtual Environment

```bash
python -m venv venv
```

Activate:

Windows:

```bash
venv\Scripts\activate
```

Mac/Linux:

```bash
source venv/bin/activate
```

---

## 3Ô∏è‚É£ Install Dependencies

```bash
pip install -r requirements.txt
```

If `requirements.txt` is not present:

```bash
pip install livekit aiohttp numpy gTTS pydub
```

---

## 4Ô∏è‚É£ Install FFmpeg (Required for TTS)

### Windows:

Download from:
[https://ffmpeg.org/download.html](https://ffmpeg.org/download.html)

Add `ffmpeg/bin` to system PATH.

Verify:

```bash
ffmpeg -version
```

---

# Required Environment Variables

üîë Configuration

## 1Ô∏è‚É£  Copy the example configuration file:

copy config.example.py config.py   # Windows

or

cp config.example.py config.py     # Mac/Linux

## 2Ô∏è‚É£   Open config.py and fill in your credentials.
```

---

# How To Run

Start the agent:

```bash
python main.py
```

Then:

1. Join the same LiveKit room from browser
2. Speak into microphone
3. Agent will respond:

   ```
   You said: <your speech>
   ```

---

# Technical Design Decisions

### 1Ô∏è‚É£ Voice Activity Detection

* RMS energy-based detection
* Frame smoothing using consecutive speech frames
* Silence window of 800ms before ending segment

### 2Ô∏è‚É£ No Overlap Handling

* Maintains `agent_speaking` state
* Cancels TTS async task on user speech
* Prevents simultaneous speaking

### 3Ô∏è‚É£ Real-Time Audio Streaming

* 20ms frame chunks
* Proper 48kHz mono 16-bit PCM format
* Silence padding for final chunk

---

# Known Limitations

* RMS-based VAD (not ML-based)
* Uses non-streaming STT (AssemblyAI polling)
* Uses non-streaming TTS (gTTS) ‚Üí 1‚Äì2s latency
* Network latency depends on external APIs
* Designed for demonstration and evaluation purposes. Not production-optimized.

---

# Assignment Evaluation Alignment

* This implementation focuses on:
* Real-time audio streaming using 20ms frame chunks
* Strict speaking-state management to prevent overlap
* Immediate interruption using async task cancellation
* Modular architecture with clear separation of concerns
* Explicit silence detection logic (20-second inactivity rule)